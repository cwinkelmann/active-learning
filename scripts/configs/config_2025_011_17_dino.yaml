wandb_flag: False
wandb_project: 'herdnet'
wandb_entity: 'karisu'
wandb_run: 'dinov2_floreana_fernandina_all_val_fernandina'
wandb_tags: ['iguana','DinoV2', "all_floreana", "fernandina_val"]
# /home/cwinkelmann/work/software-data-engineering-mac/data/ISAID/
seed: 1
device_name: null

model:

  name: 'HerdNetDINOv2'

  from_torchvision: False


#  load_from: "/raid/cwinkelmann/herdnet/outputs/2025-11-17/14-15-53/best_model.pth" # https://wandb.ai/karisu/f1_alldata_all_best_DINO/runs/gonz7gta/logs?nw=nwuserkarisul # trained on single images and drone deploy of FCD and FPM
  load_from: "/raid/cwinkelmann/herdnet/outputs/2025-11-19/11-12-17/best_model.pth" # https://wandb.ai/karisu/f1_alldata_all_best_DINO/runs/gonz7gta/logs?nw=nwuserkarisul # trained on single images and drone deploy of FCD and FPM


  kwargs:
    backbone: 'timm/vit_large_patch14_dinov2.lvd142m'
    pretrained: True
    # pretrained_path: '/home/cwinkelmann/work/Herdnet/data/models/dla34_224/model_best.pth.tar'
    pretrained_path: null
    down_ratio: 4  # was two before
    head_conv: 64 # was 64
    output_channels: [768, 1024, 1280]
    attention_layers: [-8, -6, -4, -3, -2, -1]

freeze: False # Freeze the model, if you want to train only the heads
freeze_backbone: False # Freeze the backbone, if you want to train only the heads

losses:
  FocalLoss:
    print_name: 'focal_loss'
    from_torch: False
    output_idx: 0
    target_idx: 0
    lambda_const: 1.0
    kwargs:
      alpha: 4
      beta: 1
      reduction: 'mean'
      normalize: False

  CrossEntropyLoss:
    print_name: 'ce_loss'
    from_torch: True
    output_idx: 1
    target_idx: 1
    lambda_const: 1.0
    kwargs:
      reduction: 'mean'
      weight: [10.0,   # 1 # iguana
               5.,    # 2 # hard negative
               15.,   # 3
#               1.,    # 4
#               0.1,   # 5
#               0.1,   # 6
#               1.0,   # 7
#               1.0    # 8 # background
      ] # One weight for each class including the background
      #weight: [0.9, 0.001, 1.0] # From the notebook

datasets:
  img_size: [512, 512] # The size of how the images should be processed, mostly important for the tiled prediction
  anno_type: 'point'
  num_classes: 3 # One class more for the background
  collate_fn: null


  class_def:
    1: 'iguana_point'
    2: 'hard_negative' # these next 6 are just there so I can use the pretrained model
#    3: 'Kob'
#    4: 'Warthog'
#    5: 'Waterbuck'
#    6: 'Elephant'
#    7: 'Impala'

  train:
    name: 'CSVDataset'

    csv_file: '/home/cwinkelmann/work/Herdnet/data/2025_08_10_endgame_floreana/Floreana_Fernandina_s_detection/train/herdnet_format_points.csv'
    root_dir: '/home/cwinkelmann/work/Herdnet/data/2025_08_10_endgame_floreana/Floreana_Fernandina_s_detection/train/Default'

    sampler: null
    augmentation_multiplier: 35

    albu_transforms:
      ObjectAwareRandomCrop:
        height: 1000
        width: 1000
        p: 1.0
        attempts: 10
        edge_black_blobs: true
      RandomScale:
        scale_limit:
          - 0.8
          - 1.2
        p: 0.5
      ShiftScaleRotate:
        shift_limit: 0.1
        scale_limit: 0.15
        rotate_limit: 45
        p: 0.5
        border_mode: 4
      Perspective:
        scale:
          - 0.05
          - 0.15
        p: 0.3
      Affine:
        scale:
          - 0.9
          - 1.1
        translate_percent:
          - 0.1
          - 0.1
        rotate:
          - -45
          - 45
        shear:
          - -10
          - 10
        p: 0.2
      HorizontalFlip:
        p: 0.2
      VerticalFlip:
        p: 0.2
      MotionBlur:
        p: 0.2
      RandomRotate90:
        p: 0.5
      RandomBrightnessContrast:
        brightness_limit: 0.2
        contrast_limit: 0.2
        p: 0.1
      Blur:
        blur_limit: 15
        p: 0.1
      ToGray:
        p: 0.1
      ObjectAwareRandomCropEdgeBlackout:
        height: 512
        width: 512
        p: 1.0
        attempts: 10
        edge_black_blobs: true
      Normalize:
        p: 1.0
    end_transforms:
      MultiTransformsWrapper:
        FIDT:
          num_classes: ${datasets.num_classes}
          down_ratio: ${model.kwargs.down_ratio}
          radius: 1
        PointsToMask:
          radius: 2
          num_classes: ${datasets.num_classes}
          squeeze: true
          down_ratio: 32

  validate:
    name: 'CSVDataset'

    csv_file: '/home/cwinkelmann/work/Herdnet/data/2025_08_10_endgame_floreana/Fernandina_s_detection/val/herdnet_format_points.csv'
    root_dir: '/home/cwinkelmann/work/Herdnet/data/2025_08_10_endgame_floreana/Fernandina_s_detection/val/Default'


    # data/FLPC01-07_orthomosaic_herdnet/jpg_tiles
    albu_transforms:
      Normalize:
        p: 1.0

    end_transforms:
      DownSample:
        down_ratio: ${model.kwargs.down_ratio}
        anno_type: ${datasets.anno_type}

  test:
    name: 'CSVDataset'

    csv_file: '/home/cwinkelmann/work/Herdnet/data/2025_07_10_Floreana_val_corrected/Floreana_detection_corrected/train/herdnet_format_points.csv'
    root_dir: '/home/cwinkelmann/work/Herdnet/data/2025_07_10_Floreana_val_corrected/Floreana_detection_corrected/train/Default'
    tile_size: 5000

    albu_transforms:
      Normalize:
        p: 1.0
    end_transforms:
      DownSample:
        down_ratio: ${model.kwargs.down_ratio}
        anno_type: ${datasets.anno_type}


training_settings:
  trainer: 'Trainer'
  epochs: 100
  valid_freq: 1
  print_freq: 25
  batch_size: 20
  # optimizer: 'SGD'
  optimizer: 'adamW'
  lr: 0.0001
  weight_decay: 0.0005
  num_workers: 24
  auto_lr:
    mode: 'max'
    patience: 5
    threshold: 1e-4
    threshold_mode: 'rel'
    cooldown: 20
    min_lr: 1e-8
    verbose: True
  warmup_iters: 1000


  vizual_fn: visualize_sample
  visualiser:
    name: 'HeatMapVisualizer'
    output_dir: "/raid/cwinkelmann/mosaic_prediction/FLPC01-07_22012021/predictions"



  evaluator:
    name: 'HerdNetEvaluator'
    threshold: 25
    select_mode: 'max'
    validate_on: 'f5_score'
    kwargs:
      print_freq: 100
      lmds_kwargs:
        kernel_size: [9, 9]
        adapt_ts: 0.3
        neg_ts: 0.1
        scale_factor: 1 # was 8 in the non patching case TODO fix this so it is 8 for single use and 1 for patching
        # scale_factor_patching: 1
        up: True

  stitcher:
    name: 'HerdNetStitcher'
    kwargs:
      overlap: 120
      down_ratio: ${model.kwargs.down_ratio}
      up: False
      reduction: 'mean'
  #stitcher: null

hydra:
  run:
    dir: /raid/cwinkelmann/herdnet/predictions/${now:%Y-%m-%d}/${now:%H-%M-%S}

